{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_week4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMlZ/FtJ8RBMJW0ymc+lYds",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngoc-diem/machine-learning-course/blob/master/Homework_week4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7kNQaSHWoJ1"
      },
      "source": [
        "# load our dataset\r\n",
        "from sklearn.datasets import load_iris\r\n",
        "data = load_iris()\r\n",
        "X, Y = data['data'], data['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owUJQ2eLW-aZ"
      },
      "source": [
        "# split our data into training and testing set with 90:10 ratio\r\n",
        "# use a fixed random state for reproducible results\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X55Jbce1XCth"
      },
      "source": [
        "# z-score normalization.\r\n",
        "# Remember to scale the training and test set separately to avoid data snooping.\r\n",
        "# We use the training set's mu and sigma for the test set.\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(x_train)\r\n",
        "x_train = scaler.transform(x_train)\r\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYXgJ_cjXFwV"
      },
      "source": [
        "import numpy as np\r\n",
        "from collections import Counter\r\n",
        "# Remember, no training is needed for KNN!\r\n",
        "def evaluateKNN_single(k, x_train, y_train, data):\r\n",
        "    '''\r\n",
        "    Evaluate the classification for `data` with k-nearest neighbor\r\n",
        "    given training set (x_train, y_train).\r\n",
        "\r\n",
        "    Note that this function takes in one input instead of the whole\r\n",
        "    testing set.\r\n",
        "    \r\n",
        "    Input:\r\n",
        "        k      : hyperparameter for KNN\r\n",
        "        x_train: features of training set\r\n",
        "        y_train: labels of training set\r\n",
        "        data   : features of the data point to be evaluated\r\n",
        "    Output:\r\n",
        "        Classification of the input data point.\r\n",
        "    '''\r\n",
        "    \r\n",
        "    # IMPLEMENT HERE\r\n",
        "    distances = []\r\n",
        "    for i in range(x_train.shape[0]):\r\n",
        "    \r\n",
        "        euclidean_distance = np.sqrt( np.sum((x_train[i]-data)** 2))\r\n",
        "        distances.append([euclidean_distance,y_train[i]]) \r\n",
        "    distances = sorted(distances)\r\n",
        "    votes = np.array(distances)[:k,1]\r\n",
        "    vote_result = Counter(votes).most_common(1)[0][0]  \r\n",
        "    return int(vote_result)\r\n",
        "    \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x13qchkXXN2T"
      },
      "source": [
        "# Evaluation code for the whole dataset\r\n",
        "def evaluateKNN(k, x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test):\r\n",
        "    correct = sum(map(lambda x: evaluateKNN_single(k, x_train, y_train, x[0]) == x[1], zip(x_test, y_test)))\r\n",
        "    print(f'Test accuracy with k={k}: {correct/len(y_test)*100:.4f}% ({correct}/{len(y_test)})')\r\n",
        "    # return the number of correct evaluations for us to check with the solution\r\n",
        "    return correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loi6GeNDXQ1e",
        "outputId": "dc9a32d1-c29a-4465-bf7f-ee22cf13f3f3"
      },
      "source": [
        "# and let's see how good is our model with k=5\r\n",
        "assert evaluateKNN(5) == len(y_test), \"Incorrect accuracy for 5-NN!\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy with k=5: 100.0000% (15/15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QikBdlOIXU65",
        "outputId": "192700f4-bea3-4d4c-b26e-0667206613bc"
      },
      "source": [
        "# What if we use 1-NN?\r\n",
        "assert evaluateKNN(1) == len(y_test) - 1, \"Incorrect accuracy for 1-NN!\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy with k=1: 93.3333% (14/15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztBUa56cXYOZ"
      },
      "source": [
        "def get_cluster_classification(x_data, centroids):\r\n",
        "    '''\r\n",
        "    A helper function that you will need later.\r\n",
        "    Classifies the points to their nearest cluster.\r\n",
        "    \r\n",
        "    Input:\r\n",
        "        x_data   : the data points\r\n",
        "        centroids: the cluster centroids\r\n",
        "    Output:\r\n",
        "        The centroid numbers that each data point belongs to (i.e. is nearest)\r\n",
        "    '''\r\n",
        "    \r\n",
        "    # IMPLEMENT HERE\r\n",
        "    y = np.zeros(x_data.shape[0])\r\n",
        "    for i in range(x_data.shape[0]):\r\n",
        "        d = x_data[i] - centroids\r\n",
        "        d = np.linalg.norm(d, axis=1)\r\n",
        "        y[i] = np.argmin(d)\r\n",
        "\r\n",
        "    return y\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmrLE8nq0XC0"
      },
      "source": [
        "def kmeans(x_train, k, step,centroids = None):\r\n",
        "    '''\r\n",
        "    An implementation of K-means clustering.\r\n",
        "    \r\n",
        "    Input:\r\n",
        "        k      : number of clusters\r\n",
        "        x_train: training dataset\r\n",
        "        step   : number of recaliberation steps\r\n",
        "    Output:\r\n",
        "        The centroids of the clusters (a k x d matrix)\r\n",
        "    '''\r\n",
        "    \r\n",
        "    # IMPLEMENT HERE\r\n",
        "    \r\n",
        "    if centroids is None: centroids = x_train[:k]\r\n",
        "    \r\n",
        "    for i in range(step):\r\n",
        "        clusters = get_cluster_classification(x_train, centroids)\r\n",
        "        new_centroids = np.array([np.mean(x_train[clusters == j], axis = 0) for j in range(k)])\r\n",
        "        if np.allclose(new_centroids, centroids): break\r\n",
        "        centroids = new_centroids\r\n",
        "    return centroids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmd1Vbrz0ZeS"
      },
      "source": [
        "# we know that there are three classes\r\n",
        "centroids = kmeans(x_train, k=3, step=10)\r\n",
        "assert np.allclose(centroids, np.array([\r\n",
        "    [-1.02028733,  0.90854287, -1.32521428, -1.27540932],\r\n",
        "    [ 0.99363929,  0.01896468,  0.90355632,  0.92076921],\r\n",
        "    [-0.22539812, -1.02749927,  0.23322382,  0.15491878]\r\n",
        "])), \"Incorrect centroids for K-means!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAYzbXflUqyf"
      },
      "source": [
        "\r\n",
        "def kmeanspp(x_train, k, step):\r\n",
        "    '''\r\n",
        "    An implementation of K-means++ clustering.\r\n",
        "    \r\n",
        "    Input:\r\n",
        "        k      : number of clusters\r\n",
        "        x_train: training dataset\r\n",
        "        step   : number of recaliberation steps\r\n",
        "    Output:\r\n",
        "        The centroids of the clusters (a k x d matrix)\r\n",
        "    '''\r\n",
        "    # initialize the centroids according to the above criteria\r\n",
        "    \r\n",
        "    # IMPLEMENT HERE\r\n",
        "    ...\r\n",
        "    \r\n",
        "    # the rest should be identical to kmeans()\r\n",
        "    \r\n",
        "    # IMPLEMENT HERE\r\n",
        "    centroids = [x_train[3]]\r\n",
        "    for i in range(k-1):\r\n",
        "        distances = np.array([np.sqrt(((np.array(centroids) - x_i)**2).sum(axis = 1)).tolist() for x_i in x_train])\r\n",
        "        dist_min = np.min(distances, axis = 1)\r\n",
        "        index_max = np.argsort(dist_min)[-4]\r\n",
        "        centroids.append(x_train[index_max, :].tolist()) \r\n",
        "        \r\n",
        "    return kmeans(x_train, k, step, centroids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU9jVAzHU0P2"
      },
      "source": [
        "# now check if you did it correctly.\r\n",
        "centroidspp = kmeanspp(x_train, k=3, step=10)\r\n",
        "assert np.allclose(centroidspp, np.array([\r\n",
        "    [-0.0118057 , -0.87997489,  0.36942197,  0.30573876],\r\n",
        "    [ 1.15200055,  0.18878042,  0.98903982,  1.01136932],\r\n",
        "    [-1.03358934,  0.84835232, -1.32732076, -1.27380566]\r\n",
        "])), \"Incorrect centroids for K-means++!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiIthh1UfoJF"
      },
      "source": [
        "def get_cluster_label(centroids, x_train, y_train):\r\n",
        "    '''\r\n",
        "    Get the classification for each cluster using training set.\r\n",
        "    \r\n",
        "    Input:\r\n",
        "        centroids: the centroids of the clusters\r\n",
        "        x_train  : features of training set\r\n",
        "        y_train  : labels of training set\r\n",
        "    Output:\r\n",
        "        The classifications for the clusters.\r\n",
        "    '''\r\n",
        "    # remember to return a numpy array instead of a Python list!\r\n",
        "    \r\n",
        "    # IMPLEMENT HERE\r\n",
        "    clusters = get_cluster_classification(x_train, centroids)\r\n",
        "    return np.array([Counter(y_train[clusters == i]).most_common(1)[0][0] for i in range(len(centroids))])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAfmrC1Wfo7Y"
      },
      "source": [
        "labels = get_cluster_label(centroids, x_train, y_train)\r\n",
        "labelspp = get_cluster_label(centroidspp, x_train, y_train)\r\n",
        "# each cluster nicely belongs to a different class\r\n",
        "assert (labels == [0, 2, 1]).all(), \"Incorrect K-means cluster label(s)!\"\r\n",
        "assert (labelspp == [1, 2, 0]).all(), \"Incorrect K-means++ cluster label(s)!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPOlAU3Cfryo"
      },
      "source": [
        "def evaluate_kmeans_classification(centroids, labels, x_data):\r\n",
        "    '''\r\n",
        "    Get the classification for each data point using centroid labels.\r\n",
        "    \r\n",
        "    Input:\r\n",
        "        centroids: the centroids of the clusters\r\n",
        "        labels   : the labels for the clusters\r\n",
        "        x_data   : the data to be classified\r\n",
        "    Output:\r\n",
        "        The classifications for the data.\r\n",
        "    '''\r\n",
        "    \r\n",
        "    # IMPLEMENT HERE\r\n",
        "    distances = np.array([np.sqrt(((np.array(centroids) - x_i)**2).sum(axis = 1)).tolist() for x_i in x_data])\r\n",
        "    min_centroids = np.argmin(distances, axis = 1)\r\n",
        "    return np.array([labels[i] for i in min_centroids])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arvP_RrLfwTP"
      },
      "source": [
        "# evaluate the classifications\r\n",
        "y_train_pred = evaluate_kmeans_classification(centroids, labels, x_train)\r\n",
        "y_test_pred = evaluate_kmeans_classification(centroids, labels, x_test)\r\n",
        "y_train_pred_pp = evaluate_kmeans_classification(centroidspp, labelspp, x_train)\r\n",
        "y_test_pred_pp = evaluate_kmeans_classification(centroidspp, labelspp, x_test)\r\n",
        "\r\n",
        "# and check for correctness\r\n",
        "assert (y_train_pred == [2, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 2, 1, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 2, 0, 2, 0, 0, 2, 1, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 2, 1, 2, 1, 1, 2, 1, 2, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 1, 2, 1, 2, 0, 1, 1, 0, 1, 2]).all()\r\n",
        "assert (y_test_pred == [1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0]).all()\r\n",
        "assert (y_train_pred_pp == [2, 2, 1, 1, 2, 0, 1, 0, 2, 2, 2, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 0, 0, 1, 2, 0, 1, 0, 0, 2, 1, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 1, 2, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2]).all()\r\n",
        "assert (y_test_pred_pp == [1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0]).all()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTYn1VQSfzIs",
        "outputId": "cabef238-5508-4c85-ea3d-f130223e5606"
      },
      "source": [
        "# evaluate prediction accuracy\r\n",
        "print('[+] For K-means:')\r\n",
        "train_score = np.sum(y_train_pred == y_train)\r\n",
        "print(f'Training accuracy: {train_score / len(y_train) * 100:.4f}% ({train_score}/{len(y_train)})')\r\n",
        "train_score = np.sum(y_test_pred == y_test)\r\n",
        "print(f'Training accuracy: {train_score / len(y_test) * 100:.4f}% ({train_score}/{len(y_test)})')\r\n",
        "print('[+] For K-means++:')\r\n",
        "train_score = np.sum(y_train_pred_pp == y_train)\r\n",
        "print(f'Training accuracy: {train_score / len(y_train) * 100:.4f}% ({train_score}/{len(y_train)})')\r\n",
        "train_score = np.sum(y_test_pred_pp == y_test)\r\n",
        "print(f'Training accuracy: {train_score / len(y_test) * 100:.4f}% ({train_score}/{len(y_test)})')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[+] For K-means:\n",
            "Training accuracy: 82.9630% (112/135)\n",
            "Training accuracy: 93.3333% (14/15)\n",
            "[+] For K-means++:\n",
            "Training accuracy: 80.0000% (108/135)\n",
            "Training accuracy: 93.3333% (14/15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "4NTSpDu4f5rz",
        "outputId": "6f0ec52c-ac51-4ea3-c2d7-2af9d494b5f0"
      },
      "source": [
        "# and plot out confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sn\r\n",
        "\r\n",
        "plt.figure(figsize=(10,10))\r\n",
        "fig = plt.subplot(2, 2, 1)\r\n",
        "sn.heatmap(confusion_matrix(y_train, y_train_pred), annot=True, cbar=False, square=True, linewidths=0.5)\r\n",
        "fig.set_title('K-means, train set')\r\n",
        "\r\n",
        "fig = plt.subplot(2, 2, 2)\r\n",
        "sn.heatmap(confusion_matrix(y_test, y_test_pred), annot=True, cbar=False, square=True, linewidths=0.5)\r\n",
        "fig.set_title('K-means, test set')\r\n",
        "\r\n",
        "fig = plt.subplot(2, 2, 3)\r\n",
        "sn.heatmap(confusion_matrix(y_train, y_train_pred_pp), annot=True, cbar=False, square=True, linewidths=0.5)\r\n",
        "fig.set_title('K-means++, train set')\r\n",
        "\r\n",
        "fig = plt.subplot(2, 2, 4)\r\n",
        "sn.heatmap(confusion_matrix(y_test, y_test_pred_pp), annot=True, cbar=False, square=True, linewidths=0.5)\r\n",
        "fig.set_title('K-means++, test set');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkYAAAJOCAYAAABSjsgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXiU5dn+8fOaLBBAgoiyCyguuFRpBfVtbdEiuCH6arHWrb5WVLB1qVuV+tZWqpWK4k9bUVuktaK4VOtu6+u+goqKWJVNSAAVEdkCyUzu3x9zSSMSEsgkd57J93Mcc5iZZ2aeMzeZizPPPIMWQhAAAACkVOwAAAAAzQXFCAAAwFGMAAAAHMUIAADAUYwAAAAcxQgAAMBRjJAIZnapmd0WOwcAIL9RjCIxs/lmNrjG9R+a2edm9r2YuRqDmT1jZj9pyHOEEH4bQmjQc2yuDf+MAHwds2yLnmeQmZXlItNGnpu51UAUo2bAzE6RdJOkw0MIz8bO09TMrDB2BgAN19JnGfIDxSgyMztD0rWShoYQXqrlPsHMRpnZh2a20sx+Y2Y7mtlLZrbCzKaaWXGN+x9hZjPMbLnf5xs1tl1iZnP8eWaZ2dE1tv3YzF4ws9/7b3zzzOzQDbbP9cfOM7MT6vH9jZV0gKQbzWyVmd1Y43sabWYfSvrQb5tgZgv9e3rdzA6o8Ty/MrM7/Ove/vhTzGyBmS01s8s2keEw/15Xmlm5mV1Q11qZ2V8lbS/pIc99UV3fK9CSteBZtquZ/dPMlpnZ+2Y2osZjvjZ7zKytpMckdfPnWWVm3TayP+ZWLCEELhEukuZLuk/Sx5L2quO+QdKDktpL2l3SOklPSdpBUqmkWZJO8fv2l/SJpH0lFUg6xffVyrf/QFI3ZUvxcZJWS+rq234sqUrS6f7YsyQtkmSS2kpaIWkXv29XSbvX83t9RtJPNvI9/VNSR0klftuJkraRVCjp55KWSGrt234l6Q7/urc//lZJJZL28jXpV8v+F0s6wL/eWtI367lW8yUNjv2zwoVLc7605Fnmz7VQ0qk+t/pLWippN99e2+wZJKmsjn0xtyJdOGIU18GSXpH0Tj3ue00IYUUI4V1JMyU9GUKYG0L4QtnfPvr7/UZKmhhCeDWEkAkhTFZ2+OwnSSGEe0IIi0II1SGEu5U9WjOwxn4+CiHcGkLISJqs7NDo7NuqJe1hZiUhhMWepSGuCiEsCyFUeLY7QgifhRDSIYRrJbWStMsmHn9FCKEihPCWpLeULUgbUyVpNzNrH0L4PITwht++ybUCUG8tdZYdIWl+CGGSz603lS2JP/Dttc2e+mBuRUIxiussSTtLus3MTJLM7N0ah1cPqHHfj2t8XbGR6+38616Sfu6HWJeb2XJJPZX9zUpmdnKNQ7DLJe0hqVON51ry5RchhDX+ZbsQwmplfys7U9JiM3vEzHZt2LevhTWv+GHm98zsC89WukG2DS2p8fUa/WcNNnSMpMMkfWRmz5rZ/n77JtcKQL211FnWS9K+G2Q8QVIX317b7KkP5lYkFKO4Ppb0fWXft/6DJIUQdg8htPPL81vwnAsljQ0hdKhxaRNCmGJmvZR9++lsSduEEDoo+xub1eeJQwhPhBAOVvY3r3/7c9XroXXd7oPzIkkjJG3t2b6ob7ZN7jyEaSGE4ZK2k/SApKm+qda1qiM3gK9qqbNsoaRnN8jYLoRwlu+nttlT52xhbsVDMYoshLBI2YFyiJldl4OnvFXSmWa2r2W1NbPDzWwrZd8PD5I+lSQzO1XZ37LqZGadzWy4nzi4TtIqZQ9H1zwZunctD/9Y2XMINmUrSWnPVmhmlyt7HkKDmFmxmZ1gZqUhhCplzy2o9s2bWqv65gagFjvLHpa0s5mdZGZFfhlgZv3qmD0fS9rGzEprycjciohi1AyEEBZIOkjSsWZ2VQOfa7qyJxzeKOlzSbOVPRFRIYRZyn5q5GVlXzx7Snqxnk+dknS+sicwLpP0PWUPn0vZw7gfSSqv5bETlP3ePjezG2q5zxOSHpf0gT/XWm3wVlsDnCRpvpmtUPbw+QnSptfKXSVpjB+uvkAANqmlzbIQwkpJQyT90J9viaTfKXt+pFT77Pm3pCmS5vp82djbYMytSCwEjrqhYcxsjKRPQwgTY2cBgC3FLINEMQIAAFiPt9IAAAAcxQgAAMBRjAAAAFxT/M87OYkJyE8N/jemEoIZBuSnjc6wJvm/mlctndsUu8lrRZ12UElJr9gxEq+i4iNJUmFx98hJki9dWdsnmvML86vhijpl/1kdXncNl64sZx1zYFPzi7fSAAAAHMUIAADAUYwAAAAcxQgAAMBRjAAAABzFCAAAwFGMAAAAHMUIAADAUYwAAAAcxQgAAMBRjAAAABzFCAAAwFGMAAAAHMUIAADAUYwAAAAcxQgAAMBRjAAAABzFCAAAwFGMAAAAHMUIAADAUYwAAAAcxQgAAMBRjAAAABzFCAAAwFGMAAAAHMUIAADAUYwAAAAcxQgAAMBRjAAAABzFCAAAwFGMAAAAHMUIAADAUYwAAAAcxQgAAMBRjAAAAFyLLUaZTEbH/ni0Rl34v5KkX151nf77lFE6+uSzdN5lV2rNmorICZPl5pvH6aOPXtf06U/GjpJ4Q4cM0rszn9O/Z72giy4cHTsOmrEVK1fpvMuu1LDjT9ewH43UjJnvxY6UWLzuciMf1rHFFqM77nlQO/Tefv31i382UvdP/oP+/pc/qmvn7XTnfQ9FTJc8f/3rPRo+/JTYMRIvlUrphgljdcSwE7XnXgfquOOOUr9+O8WOhWbq6utv1rf33UcPTblV90++STv06hk7UiLxusuNfFnHFlmMlnzyqZ576TUdM2zo+tvatW0rSQohaO26dTKLlS6ZXnzxNS1btjx2jMQbOKC/5syZr3nzFqiqqkpTpz6oI2v8nAJfWrlqtV5/a+b6OVZUVKT2W7WLnCqZeN3lRr6sY2FddzCzXSUNl9TdbyqX9I8QQmKP2f5uwkSdP+o0rd7g7bIxY8fruZenacfe2+vCn54eKR1asm7du2hh2aL118vKF2vggP4REyVbPs6vL5UvWqKtO5RqzNjxen/2XO22y0665Nwz1aakdexoicPrLjfyZR03ecTIzC6WdJckk/SaX0zSFDO7ZBOPG2lm081s+i233JLLvA32zIuvquPWHbT7rl8/vHflZefr6Qfv0A69e+rxp56LkA5Armzp/PLHrp9ht/1lSuOH3QLpTEbvfTBbxx19uO69/SaVlLTWn/46NXYsIPHqOmJ0mqTdQwhVNW80s/GS3pV09cYeFEK4RdKXjShULZ3b0Jw58+bbs/TMC6/o+ZenaV1llVavXqOLr7hGv/vfiyRJBQUFOnTw9/Tnv92row8fEjktWppF5UvUs0e39dd7dO+qRYuWREyUaFs0v6SvzrCqpXNDY4bcUl2266TO23bSN3bfVZI0ZNB3dNsdFKMtwesuN/JlHes6x6haUreN3N7VtyXOeWedqqceuENP3jdZ4664RAO/tZeuvvxCLfDDfyEEPf3CK+rTq0fkpGiJpk2fob59+6h3754qKirSiBHD9dDDfNJvC+Xd/Kqp0zYd1WW7bTXvozJJ0iuvz9CONT5QgvrjdZcb+bKOdR0xOlfSU2b2oaSFftv2kvpKOrsxgzWlEIIuvfJarV69RiEE7dK3j355Yd58e01i8uQbdMAB+6tTp601e/Yr+s1vrtPkyXfHjpU4mUxG55w7Ro8+cqcKUindPvluzZr1QexYSZX38+vS887SxVdco6p0lXp266rfXHpe7EiJxOsuN/JlHS2ETR8lNrOUpIH66smL00IImXruo1m9lZZURZ12UElJr9gxEq+i4iNJUmFx9zruibqkK8ub/Wc3czC/mu1baUlS1GkHSbzuciFdWc465kC6slzKnnP4NXV+Ki2EUC3plRxnAoBGx/wCsLla5L9jBAAAsDEUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFkJo7H00+g4ARGGxAzQRZhiQnzY6wwqbYs+Fxd2bYjd5LV1ZrpXnDosdI/G2uv4hSdKve50QOUnyXf7R32JHaBLMr4ZLV5ZLkiruvTJykuQrOXaMBvUYHDtG4j1T9q9at/FWGgAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAALjC2AFiGzpkkMaP/7UKUin9edIUXTPuptiRkqGwSG1+erVUWCSlCpR+60VVPn6nrGNnlZxyoazNVsqUzdHaO8ZLmXTstM3asHGna+eD+mv1Zyt085BLvrJtv9MP05AxJ2jc3meo4vNVkRKiuWJ+5c6h4+5X21ZFSpmpMGW6c/ThsSMlzkW/v0D7D95Xy5cu16mDT48dZ4u16GKUSqV0w4SxOuSw41VWtlivvPyoHnr4Sb333oexozV/6SqtuekyqXKtlCpQm3N+p/R7r6t40FGqfOZBpd98Xq1+MEpF+x2sqhcfi522WXvrnuc1bfI/ddT4M79ye/uuHbXjAXtqednSSMnQnDG/cu/W0w7W1m1bx46RWI/f84T+fvsDuvT6i2NHaZAW/VbawAH9NWfOfM2bt0BVVVWaOvVBHTlsaOxYyVG5NvvfgkIpVSgpqGCnbyj91ouSpKppT6lwz/3i5UuIBa/9WxXLv340aMjlJ+lfV02RQoiQCs0d8wvNzduvvqOVy1fGjtFgW1yMzOzUXAaJoVv3LlpYtmj99bLyxerWrUvERAljKbW5cILaXflXpT94U2HpEqlilVRdLUkKyz+TlW4TOWQy7Xzwt7RyyTJ9/N6C2FHyVtJnGPMrt8yksyY9peNvekT3vvZB7DiIqCFvpV0hadLGNpjZSEkjJWnixIkN2AWatVCtNePOkUraquR/LlVmux6xE+WFwtbFOmD0kbrjpKtjR8l39ZphVlCqVKptU+ZCBJNOP0SdS9to2aoKnTnpKfXZtlTf6tM5dixEsMliZGZv17ZJUq0/MSGEWyTd8uXVUWdfsWXpGtmi8iXq2aPb+us9unfVokVLIiZKqIrVysx+R6neu0gl7aRUSqqulnXYRuGLz2KnS5yOvTqrQ89tdcZjV0nKnms08pGxum345Vr96ReR0yVLLmZYYXH3ZvleJvMrtzqXtpEkdWxXogN366mZZUspRi1UXUeMOksaKunzDW43SS81SqImNG36DPXt20e9e/dUefkSjRgxXCedPDp2rESwtu0VqjNSxWqpqFgFO++tyqfuU2b22yrc69tKv/m8igZ8X+l3Xo0dNXE+eX+hrv3WqPXXf/bC9bp12Bg+lbZl8naGMb9yp6KyStVBatuqSBWVVXp59mKdceCesWMhkrqK0cOS2oUQZmy4wcyeaZRETSiTyeicc8fo0UfuVEEqpdsn361Zs3hvuT6sfUeVnHBu9uiQpZSe8YIys6ap+uMFKjn5IrU67ERlyueq6pUnY0dt9v77htHqtX8/tdl6K537yv/TM9fdqxl3Pxs7Vr7I2xnG/Mqdz1at1fl/y77m0tXVOvQbffTtnbtHTpU8v7zxUu29/14q7Viqe6ZN0aRrJ+vRux6PHWuzWWj8T7yEwmJ+wBoqXVmulecOix0j8ba6/iFJ0q97nRA5SfJd/tHfLHaGptBc30pLknRluSSp4t4rIydJvpJjx2hQj8GxYyTeM2X/krJHjr+mRX9cHwAAoCaKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4CyE09j4afQcAorDYAZoIMwzITxudYRwxAgAAcIVNspPi7k2xm7yWrizX0J6Hxo6ReE8sfEyStPa1eyInSb7WA38QO0KTYH41XLqyXBJrmQvpynJN73FU7BiJt0/ZA7Vu44gRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgCuMHSC2oUMGafz4X6sgldKfJ03RNeNuih0pkY7+yVE69IeHKCho3r/n69qfj1fVuqrYsRJhXWWVTh17m6qqMkpXV+vgAbtr1DHf16vvztH4KY+rKp3Rbn266Vc/OVqFBQWx46IZYX7lDmvZcNaqSLveN1ZWXCQrKNDnj76kRdfeFTvWZmvRR4xSqZRumDBWRww7UXvudaCOO+4o9eu3U+xYibNNl2101KnDdfYRP9MZg89SQSqlQUd+L3asxCguKtRtv/gf3fPbszX1ytF68e0PNeODBfrlLffpd6OP0/1X/0xdO3XQP55/M3ZUNCPMr9xhLXMjrKvS+yMu16wh52nW0PPUftA31fabO8eOtdnqLEZmtquZfd/M2m1w+yGNF6tpDBzQX3PmzNe8eQtUVVWlqVMf1JHDhsaOlUgFhQVq1bpYqYKUWpW00mcfL4sdKTHMTG1at5IkpTMZpTMZpVKmosIC9e7aSZK0/x599dS0WTFjJhLzC/XBWuZO9Zq1kiQrLJAVFkghRE60+TZZjMzsZ5IelPRTSTPNbHiNzb9tzGBNoVv3LlpYtmj99bLyxerWrUvERMn02ZLPdO/E+/TXV/6iKa/fqdUr1+iN596IHStRMtXVGnHZjTpw9NXab4++2nPHHspkqvXu3HJJ0j9fe1dLln0ROWWyML9QX6xlDqVS2u2J67TXW5O14vm3tPrND2Mn2mx1nWN0uqRvhRBWmVlvSfeaWe8QwgRJVtuDzGykpJGSNHHixBxFRXPVrrSd9h+yn075r1O1asUqjbn5Uh109IH6v78/HTtaYhSkUpo69mytWF2h8ybcqdlln+h3o4/TuL89qsp0Wv+1R18VpGp9yWHjtmh+SV+dYVZQqlSqbWNnBfJDdbVmDT1PBe3basfbLlHrXbbX2vcXxE61WeoqRqkQwipJCiHMN7NByg6XXtrEYAkh3CLpli+vjjr7ilxkzblF5UvUs0e39dd7dO+qRYuWREyUTP2/s7eWLPxYX/gRjRcfe0m77bMbxWgLtG9bogH9+uiltz/UKYd/R7f/8nRJ0kvvfKiPlnwWOV3ibNH88vuvn2GFxd2b5XsBzK/cYS1zL7NitVa+9I5KB/VPXDGq6xyjj81s7y+v+JA5QlInSXs2ZrCmMG36DPXt20e9e/dUUVGRRowYrocefjJ2rMT5pPxT9eu/q1r5eTJ7f3tvLfhwYeRUybFsxWqtWF0hSVpbWaVXZs5R726d9NkXqyRJlVVpTXr4eR170ICYMZOI+YV6YS1zo7BjexW0zx5dtdbFan/A3lo7uzxyqs1X1xGjkyWla94QQkhLOtnMEv8eWSaT0TnnjtGjj9ypglRKt0++W7NmfRA7VuK8P+N9Pf/oC7rpsf+nTCaj2TPn6LE7H4sdKzGWLl+pMbfcp+rqalVXBw3Zdw99r/+uGj/lcT03431VVweN+P5A7bv7jrGjJg3zC/XCWuZGUeet1ee6c6SClMxMyx5+UV88NT12rM1mofHPGA+Fxd0bex95L11ZrqE9D40dI/GeWJgtbGtfuydykuRrPfAHLeKkp+b6VlqSpCuzRw34u6Dh0pXlmt7jqNgxEm+fsgekWt5Sb9H/jhEAAEBNFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAAZyGE2BmiM7ORIYRbYufIB6xlbrCO2Bz8vOQG65gbSV9HjhhljYwdII+wlrnBOmJz8POSG6xjbiR6HSlGAAAAjmIEAADgKEZZiX0vtBliLXODdcTm4OclN1jH3Ej0OnLyNQAAgOOIEQAAgKMYAQAAuBZfjMzsEDN738xmm9klsfMklZn92cw+MbOZsbMkmZn1NLOnzWyWmb1rZufEzoTmi/mVG8yv3MiX+dWizzEyswJJH0g6WFKZpGmSjg8hzIoaLIHM7LuSVkn6Swhhj9h5ksrMukrqGkJ4w8y2kvS6pKP4mcSGmF+5w/zKjXyZXy39iNFASbNDCHNDCJWS7pI0PHKmRAohPCdpWewcSRdCWBxCeMO/XinpPUnd46ZCM8X8yhHmV27ky/xq6cWou6SFNa6XKYF/iMhPZtZbUn9Jr8ZNgmaK+YVmK8nzq6UXI6BZMrN2ku6TdG4IYUXsPABQX0mfXy29GJVL6lnjeg+/DYjGzIqUHSp/CyHcHzsPmi3mF5qdfJhfLb0YTZO0k5n1MbNiST+U9I/ImdCCmZlJ+pOk90II42PnQbPG/EKzki/zq0UXoxBCWtLZkp5Q9iSxqSGEd+OmSiYzmyLpZUm7mFmZmZ0WO1NCfVvSSZIOMrMZfjksdig0P8yv3GF+5UxezK8W/XF9AACAmlr0ESMAAICaKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmKEvGJml5rZbbFzAACSiWKUY2Y238wG17j+QzP73My+FzNXEpjZM2b2k4Y8RwjhtyGEBj3H5trwzxzIB8yyLZeLWebPM8jMynKRaSPPzdyqBcWoEZnZKZJuknR4COHZ2HkaysxCLu+3BfsvbIznBbBpzDK0JBSjRmJmZ0i6VtLQEMJLtdwnmNkoM/vQzFaa2W/MbEcze8nMVpjZVDMrrnH/I8xshpkt9/t8o8a2S8xsjj/PLDM7usa2H5vZC2b2e/+Nb56ZHbrB9rn+2HlmdkLjrErtzGyspAMk3Whmq8zsRr89mNloM/tQ0od+2wQzW+hr9LqZHVDjeX5lZnf417398aeY2QIzW2pml20iw2G+divNrNzMLqixbaNrb2Z/lbS9pIc890WNsDxANMyyzbOJWbarmf3TzJaZ2ftmNqLGY742e8ysraTHJHXz51llZt02sj/mVq6FELjk8CJpvqT7JH0saa867hskPSipvaTdJa2T9JSkHSSVSpol6RS/b39Jn0jaV1KBpFN8X618+w8kdVO27B4nabWkrr7tx5KqJJ3ujz1L0iJJJqmtpBWSdvH7dpW0e21567kG9brfRh73jKSfbGSN/impo6QSv+1ESdtIKpT0c0lLJLX2bb+SdId/3dsff6ukEkl7+Rr3q2X/iyUd4F9vLemb9Vz7+ZIGx/7Z48IllxdmWe5mmWdbKOlUn1v9JS2VtJtvr232DJJUVse+mFs5vnDEqHEcLOkVSe/U477XhBBWhBDelTRT0pMhhLkhhC+U/W2hv99vpKSJIYRXQwiZEMJkZYfPfpIUQrgnhLAohFAdQrhb2aMrA2vs56MQwq0hhIykycoOjc6+rVrSHmZWEkJY7Fmak6tCCMtCCBWSFEK4I4TwWQghHUK4VlIrSbts4vFXhBAqQghvSXpL2YK0MVWSdjOz9iGEz0MIb/jtm1x7II8xy3LjCEnzQwiTfG69qWzp/IFvr2321AdzK8coRo3jLEk7S7rNzEySzOzdGodDD6hx349rfF2xkevt/Otekn7uh0SXm9lyST2V/c1KZnZyjUOmyyXtIalTjeda8uUXIYQ1/mW7EMJqZX8rO1PSYjN7xMx29ef8zgb7U83rZvadzblfAyysecUPM79nZl/4/ko3+F43tKTG12v0nzXd0DGSDpP0kZk9a2b7++2bXHsgjzHLcjPLeknad4PnPkFSF99e2+ypD+ZWjnEya+P4WNL3JT0r6Q+Szgoh7N7A51woaWwIYeyGG8ysl7JvF31f0sshhIyZzVD28HKdQghPSHrCzEokXenPdUAI4QVJHWrsJ4QQOmzk8fW6X32i1HW7D+KLlP1e3w0hVJvZ56rn97rJnYcwTdJwMyuSdLakqcoOklrXvo7cQNIxy3IzyxZKejaEcHAtuWubPXXOFuZW7nHEqJGEEBYp++I+xMyuy8FT3irpTDPb17LamtnhZraVsu9fB0mfSpKZnarsb1l1MrPOZjbcsif6rZO0StnD0Tln/zkZunctd/lY2XMSNmUrSWllv9dCM7tc2fMaGpqt2MxOMLPSEEKVsucqfLkOm1r7+uYGEolZttF9be4se1jSzmZ2kpkV+WWAmfWrY/Z8LGkbMyutJQdzqxFQjBpRCGGBpIMkHWtmVzXwuaYre8LhjZI+lzRb2SWdJ9wAABTwSURBVBMRFUKYpeynRl5W9od9T0kv1vOpU5LOV/YExmWSvqfs4fPG0FPSR5LKa9k+Qdm1+tzMbqjlPk9IelzSB/5ca7XBW20NcJKk+Wa2QtnD8SdIm157d5WkMX64+gIBeYZZ9jWbNctCCCslDZH0Q8+3RNLvlD0/Uqp99vxb0hRJc32+bOxtMOZWjlkIHE1D0zCzMZI+DSFMjJ0FALYUsyy/UYwAAAAcb6UBAAA4ihEAAICjGAEAALim+HeMQtXSuU2wm/xW1GkHFRZ3jx0j8dKV2Q+RsJYNl64sb/C/HZUEVUvnciJmAxV1yn4qnNddw6Ury1nHHPC/CzY6wzhiBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAK7FFqNMJqNjfzxaoy7836/c/tvr/qgBg4+OlCq5hg4ZpHdnPqd/z3pBF104OnacRGMtUV8rVq7SeZddqWHHn65hPxqpGTPfix0psXjd5UY+rGOLLUZ33POgdui9/Vdum/neB1qxclWkRMmVSqV0w4SxOmLYidpzrwN13HFHqV+/nWLHSiTWEpvj6utv1rf33UcPTblV90++STv06hk7UiLxusuNfFnHOouRme1qZheb2Q1+udjM+jVFuMay5JNP9dxLr+mYYUPX35bJZHTtTX/Sz0edFjFZMg0c0F9z5szXvHkLVFVVpalTH9SRNdYW9cda5lY+zq8vrVy1Wq+/NXP9HCsqKlL7rdpFTpVMvO5yI1/WcZPFyMwulnSXJJP0ml9M0hQzu6Tx4zWO302YqPNHnSaz/3z7d973kA78zn7atlPHiMmSqVv3LlpYtmj99bLyxerWrUvERMnFWuZOvs6vL5UvWqKtO5RqzNjxOvbHo3X5VddrTcXa2LESidddbuTLOtZ1xOg0SQNCCFeHEO7wy9WSBvq2jTKzkWY23cym33LLLbnM22DPvPiqOm7dQbvv+p/De598+pmefPp5/ejYIyMmA5BjWzS/pK/OsNv+MqVJwm6udCaj9z6YreOOPlz33n6TSkpa609/nRo7FpB4hXVsr5bUTdJHG9ze1bdtVAjhFklfNqJQtXTuFgfMtTffnqVnXnhFz788Tesqq7R69RodddKZKioq0mHH/Y8kae3adTp0xP/osal/jpw2GRaVL1HPHt3WX+/RvasWLVoSMVFysZY5tUXzS/rqDKtaOjc0SroG6rJdJ3XetpO+sfuukqQhg76j2+6gGG0JXne5kS/rWFcxOlfSU2b2oaSFftv2kvpKOrsxgzWW8846Veeddaok6bU33tbtU+7TH8Zd8ZX7DBh8NKVoM0ybPkN9+/ZR7949VV6+RCNGDNdJJyfz0wixsZY5lXfzq6ZO23RUl+221byPytSnVw+98voM7bjBB0pQP7zuciNf1nGTxSiE8LiZ7azsoefufnO5pGkhhExjh0MyZDIZnXPuGD36yJ0qSKV0++S7NWvWB7FjJRJrmTstYX5det5ZuviKa1SVrlLPbl31m0vPix0pkXjd5Ua+rKOF0OhHiZvVW2lJVdRpBxUWd6/7jtikdGW5JLGWOZCuLLfYGZpCc30rLUmKOu0gidddLqQry1nHHPC/CzY6w1rsv2MEAACwIYoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADiKEQAAgKMYAQAAOIoRAACAoxgBAAA4ihEAAICjGAEAADgLITT2Php9BwCisNgBmggzDMhPG51hHDECAABwhU2yk+LuTbGbvJauLNeaCWfGjpF4bc65WZJ0fK+jIidJvikfPRA7QpNgfjVcurJcklRx75WRkyRfybFjNKjH4NgxEu+Zsn/Vuo0jRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACuMHaA2IYOGaTx43+tglRKf540RdeMuyl2pGQoKFSrYy+QFRRKqZQys99Q1SsPr99c9L0RKtztv1Txx3MjhkyGM8adrf4H7aMVn32hi4acI0lqW9pO59x0gTr12E5Lyz7RhFHjtHrF6shJ0dwwv3Ln0HH3q22rIqXMVJgy3Tn68NiREuei31+g/Qfvq+VLl+vUwafHjrPFWvQRo1QqpRsmjNURw07UnnsdqOOOO0r9+u0UO1YyZNJad/91WnvnlVp755VK9dpdqS59JEmp7baXtWoTOWByPHvP/+nqU379lduGjzpGM198W+cPGqWZL76tI0cdEykdmivmV+7detrBmvrTIyhFW+jxe57QRSf+InaMBmvRxWjggP6aM2e+5s1boKqqKk2d+qCOHDY0dqzkqFqX/W+qQJYqkEKQzFT0nWNU+cL9cbMlyL9fm6VVy1d95bZvHTxQz933tCTpufue1j5D9o0RDc0Y8wvNzduvvqOVy1fGjtFgLfqttG7du2hh2aL118vKF2vggP4REyWMmVoff6msdFul335W1R/PV+HeBykz721pzYrY6RKttFMHLf/kc0nS8k8+V2mnDpEToblhfuWWmXTWpKdkJh0zYCcdO3Dn2JEQyRYXIzM7NYQwqZZtIyWNlKSJEydu6S7Q3IWgtXeOlYpL1OqIM5Xq1lcFO31T6+4dHztZ3gkKsSPknfrOMCsoVSrVtkmzoelNOv0QdS5to2WrKnTmpKfUZ9tSfatP59ixEEFD3kq7orYNIYRbQgj7hBD2GTlyZAN20bgWlS9Rzx7d1l/v0b2rFi1aEjFRQlVWKFP2vlI9d1GqdFu1/vFv1PrUsVJRsVpvcO4M6ueLpcvVYbutJUkdtttaK5Z+ETlRXqrXDGuupYj5lVudS7PnRXZsV6IDd+upmWVLIydCLJs8YmRmb9e2SVLiq/S06TPUt28f9e7dU+XlSzRixHCddPLo2LGSoaSdlMlIlRVSQZEKtu+nqtefVMVtF//nLmddr7WTL48YMrle/9dr+u4xB+off7xf3z3mQL3+z9diR0qkfJ5hzK/cqaisUnWQ2rYqUkVllV6evVhnHLhn7FiIpK630jpLGirp8w1uN0kvNUqiJpTJZHTOuWP06CN3qiCV0u2T79asWR/EjpUI1rZUrQ4+RUqlJJnSH76u6nnvxI6VSD+94Xz1238PbbV1e934ym2697q79I8/3K9z/nChBh03WEvLP9WEUeNix0yqvJ1hzK/c+WzVWp3/t2clSenqah36jT769s7dI6dKnl/eeKn23n8vlXYs1T3TpmjStZP16F2Px4612SyE2s9dMLM/SZoUQnhhI9vuDCH8qB77CIXF/IA1VLqyXGsmnBk7RuK1OedmSdLxvY6KnCT5pnz0gMXOUJdczLDC4u6c4NVA6cpySVLFvVdGTpJ8JceO0aAeg2PHSLxnyv4lZX9B+ppNHjEKIZy2iW31KUUAEA0zDMDmatH/jhEAAEBNFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBQjAAAARzECAABwFCMAAABHMQIAAHAUIwAAAEcxAgAAcBZCaOx9NPoOAERhsQM0EWYYkJ82OsMKm2LPhcXdm2I3eS1dWa5be5wYO0binV52hyRp5ZmHRE6SfFvd/HjsCE2C+dVw6cpySaxlLqQryzW9x1GxYyTePmUP1LqNt9IAAAAcxQgAAMBRjAAAABzFCAAAwFGMAAAAHMUIAADAUYwAAAAcxQgAAMBRjAAAABzFCAAAwFGMAAAAHMUIAADAUYwAAAAcxQgAAMBRjAAAABzFCAAAwFGMAAAAHMUIAADAUYwAAAAcxQgAAMBRjAAAABzFCAAAwFGMAAAAHMUIAADAUYwAAAAcxQgAAMBRjAAAABzFCAAAwFGMAAAAHMUIAADAUYwAAAAcxQgAAMBRjAAAABzFCAAAwFGMAAAAHMUIAADAFcYOENvQIYM0fvyvVZBK6c+TpuiacTfFjpQI3/396dp+8N6qWLpC9w3+hSTpoD+crQ47dpUkFbdvo8oVa3T/0MtixkyGwiK1ueD3UmGRlCpQ+o3nVfnwHbJtOqvkJ7+QtW2vzIIPtXbSOCmTjp0WzQjzK3dYy4azVkXa9b6xsuIiWUGBPn/0JS269q7YsTZbiy5GqVRKN0wYq0MOO15lZYv1ysuP6qGHn9R7730YO1qz98E9z+nd2/+pQdefsf62/xt14/qv9/3lj1S5ck2MaMmTrtKa6y6W1q2VUgVqc+G1Sr87XcWD/1uVT/1d6enPqtWPfqqibw9V1XOPxE6LZoL5lTusZW6EdVV6f8Tlql6zVlZYoF3+fpW+ePoNrX7jg9jRNkudb6WZ2a5m9n0za7fB7Yc0XqymMXBAf82ZM1/z5i1QVVWVpk59UEcOGxo7ViIsefV9rVu+qtbtOwzbV3MefLkJEyXcurXZ/xYUZi8hqGCXvZR+43lJUtXL/1LhXv8VMWAyMb9QH6xl7lSvyc4yKyyQFRZIIUROtPk2WYzM7GeSHpT0U0kzzWx4jc2/bcxgTaFb9y5aWLZo/fWy8sXq1q1LxET5ocu+u6ji0y+0Yt7HsaMkh6XU5rKb1G7cXUq/94bCp4ulNaul6mpJUlj+qazDNpFDJgvzC/XFWuZQKqXdnrhOe701WSuef0ur30zeUbe63ko7XdK3QgirzKy3pHvNrHcIYYIkq+1BZjZS0khJmjhxYo6iIil2HL4/R4s2V6jWmrGjpZK2KjnzcmW69IydKB9s0fySvjrDrKBUqVTbxs4K5Ifqas0aep4K2rfVjrddota7bK+17y+InWqz1PVWWiqEsEqSQgjzJQ2SdKiZjdcmBksI4ZYQwj4hhH1GjhyZq6w5t6h8iXr26Lb+eo/uXbVo0ZKIiZLPClLqfegAzX3o1dhRkqlitTLvv6XUDv2kNm2lVPYlah22VVj+WeRwibNF88vvv36GNddSxPzKHdYy9zIrVmvlS++odFD/2FE2W13F6GMz2/vLKz5kjpDUSdKejRmsKUybPkN9+/ZR7949VVRUpBEjhuuhh5+MHSvRuh+wh76Ys0irFy+LHSUxrF2pVOJ/+RYVq6DfN1W9ZIEy77+twm8ekL15/8FKv81RuM3E/EK9sJa5UdixvQraZ2eZtS5W+wP21trZ5ZFTbb663ko7WdJXPh8cQkhLOtnMEv8eWSaT0TnnjtGjj9ypglRKt0++W7NmJevs+VgOvHG0uu3fT607ttPx027QG9fep/fvelY7Hrmf5jzAX+Cbw0o7quSUn0upAslM6defU+ad11S9eIFKfvILtTryFGUWzlHVi0/Ejpo0zC/UC2uZG0Wdt1af686RClIyMy17+EV98dT02LE2m4XGP2M8FBZ3b+x95L10Zblu7XFi7BiJd3rZHZKklWcm/kNJ0W118+ObfDsqXxQWd0/ex2qamXRl9qgBfxc0XLqyXNN7HBU7RuLtU/aAVMtb6vzL1wAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAACOYgQAAOAoRgAAAI5iBAAA4ChGAAAAjmIEAADgKEYAAADOQgiNvY9G3wGAKCx2gCbCDAPy00ZnWFMcMbLmfjGzM2JnyJcLa9mi1rGliL3O+fLz0uwvrGOLW8eN4q20rJGxA+QR1jI3WEdsDn5ecoN1zI1EryPFCAAAwFGMAAAAHMUo65bYAfIIa5kbrCM2Bz8vucE65kai17EpPpUGAACQCBwxAgAAcBQjAAAA1+KLkZkdYmbvm9lsM7skdp6kMrM/m9knZjYzdpYkM7OeZva0mc0ys3fN7JzYmdB8Mb9yg/mVG/kyv1r0OUZmViDpA0kHSyqTNE3S8SGEWVGDJZCZfVfSKkl/CSHsETtPUplZV0ldQwhvmNlWkl6XdBQ/k9gQ8yt3mF+5kS/zq6UfMRooaXYIYW4IoVLSXZKGR86USCGE5yQti50j6UIIi0MIb/jXKyW9J6l73FRopphfOcL8yo18mV8tvRh1l7SwxvUyJfAPEfnJzHpL6i/p1bhJ0Ewxv9BsJXl+tfRiBDRLZtZO0n2Szg0hrIidBwDqK+nzq6UXo3JJPWtc7+G3AdGYWZGyQ+VvIYT7Y+dBs8X8QrOTD/OrpRejaZJ2MrM+ZlYs6YeS/hE5E1owMzNJf5L0XghhfOw8aNaYX2hW8mV+tehiFEJISzpb0hPKniQ2NYTwbtxUyWRmUyS9LGkXMyszs9NiZ0qob0s6SdJBZjbDL4fFDoXmh/mVO8yvnMmL+dWiP64PAABQU4s+YgQAAFATxQgAAMBRjAAAABzFCAAAwFGMAAAAHMUIAADAUYwAAADc/wdCLwAeUH8B0AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}